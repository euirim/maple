import operator
import nltk
from sklearn.feature_extraction.text import TfidfVectorizer
import networkx as nx
#import matplotlib.pyplot as plt

def tfidf_matrix_generator(tokens):
    # Bag of words in vector form
    vectorizer = TfidfVectorizer(stop_words="english")
    norm_matrix = vectorizer.fit_transform(tokens)
    return norm_matrix * norm_matrix.transpose()
     

# assumes newline characters have been eliminated
def summarize(doc, max_sentences, generate_matrix):
    # tokenize sentences
    sent_tokenizer = nltk.data.load("tokenizers/punkt/english.pickle")
    sentences = sent_tokenizer.tokenize(doc)

    # matrix creation     
    matrix = generate_matrix(sentences) 

    # graph generation
    graph = nx.from_scipy_sparse_matrix(matrix)
    # nx.draw(graph)

    # PageRank
    scores = nx.pagerank_scipy(graph, max_iter=100)

    # generate summary
    pagerank = sorted(scores.items(), 
            key=operator.itemgetter(1),
            reverse=True)[:max_sentences]
    summary = sorted(pagerank)

    return 0

def tfidf_summarize(doc, max_sentences):
    summarize(doc, max_sentences, tfidf_matrix_generator)
    return 0
    
    
    


